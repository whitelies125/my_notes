### 什么是渲染管线

渲染管线，我理解就是一系列步骤流程的整合。
它的起始是我们准备数据传递给GPU，中间是各种计算，比如 vertex shader，fragment shader 等等，结束是在屏幕上绘制颜色。

我之前是参考的 OpenGL 的官网 wiki 来理解这个流程的，所以就以 OpenGL 的渲染管线流程为例吧。

首先是分为好几个阶段，我先说一下有那些阶段，然后再详细的讲一下。
第一个是 vertex specification，我自己翻译成顶点指明，因为它这个官网wiki 没有中文翻译。
然后是 vertex processing，顶点处理，vertex post-processing，顶点后处理。
然后顶点处理完了，开始 resterization 光栅化，
光栅化之后就是 fragment processing，片元处理。
最后，把着色结果进行 per-sample processing 就得到了最终结果。

OK，我再一个一个来。

第一步是 vertex specification，顶点指明。
这一步顾名思义嘛，看名字就大概知道是做什么的。主要呢，就是我们准备数据，比如设置 VAO，VBO，EBO 这些，目的是告诉 OpenGL 这些数据的来源、以及这些数据的格式，也就是如何解读这些数据，我给它的数据到底是一个三角形，还是一个三角形 strp，一个三角形带啊。

然后是 vertex processing，顶点处理。
这个阶段主要是对单个顶点进行处理，用 vertex shader 完成坐标变换，把顶点的坐标变换到观察空间，也可以在这里完成逐顶点的光照，相比逐片元的光照，性能要好一点嘛。
同时还有 Tessellation 镶嵌 和 geometry shader 几何着色器这两个可选的步骤，主要用于曲面细分，对顶点进行一些调整。比如说可以用几何着色器实现一个物体爆破的效果啊，这个是 LeanOpenGL 里的例子了。

下一个阶段就是 vertex post-prcessing，顶点后处理。
在上一个阶段，我之前说处理的数据是单个顶点，到这里的话，处理的数据就是单个 primitive 图元了。
所以首先要进行的是 primitve assembly 图元组装。
什么是图元嘛，我理解啊，就是说把几个有关联的顶点视为一个几何图形的顶点。比如说 3 个顶点，组成一个三角形图元嘛。
所以我们完成图元组装之后呢，后面的处理流程，操作的数据单元基本就是图元了。

然后则个顶点后处理，还要进行 裁剪，把这个观察空间转换到裁剪空间。
然后是透视除法，除以w，裁剪空间转换为 NDC 坐标。
面剔除，就是环绕顺序，我们定义一个正的环绕顺序，剔除掉逆方向环绕顺序的面，因为后面光栅化和那个 fragment shader 的开销比较大，能提前去掉一些面，就可以提高性能嘛。

接着下一个阶段是 rasterization 光栅化。
简单的理解，就是根据图元的覆盖范围进行一个遍历，然后遍历的每个单元/元素就是 fragment 片元。

然后对 fragment 进行处理，就到了 fragment processing 阶段。
这里处理的数据单元又发生了变化，从最开始的顶点、到图元、到现在的片元。

最后一个阶段是 per-sample processing，逐样本处理。
因为 fragment 的结果其实并不能直接对应到 pixel 像素，我们还得进行一下处理才行。
比如说 剪裁测试，就是我们只想显示某个范围内的图像。就可以用剪裁测试进行过滤。
模板测试，深度测试。
模板测试的话，LearnOpengl 里面举了一个例子，是用来实现选中物体边框高亮的。
深度测试，就很关键啊，用来处理物体的前后遮挡关系。
以及混合操作，一般是用来处理那个，透明、半透明物体的这个显示的。

OK，大致的话，我理解的渲染管线就是这样的。

### shader 是什么

shader 翻译的话是着色器嘛。
一般来讲，主要是指 vertex shader 和 fragment shader。
当然还有其他的 shader，按我看的 OpenGL 文档，还有 Tessellation 镶嵌 和 geometry shader 几何着色器，不过这两个都是可选的。

Ok，回到这个顶点和片元 shader，它们本质上的是一段可编程的交给GPU执行的程序。
当然啊，既然这两个 shader 区分出来了，有两个不同的名字，那它们的作用其实也不一样。
顶点着色器，主要是完成坐标变换，从这物体的模型空间，转换到世界空间，再到观察空间
片元着色器，主要是完成这个片元的颜色，啊，着色计算。

当然，这两个shader 都可以完成光照计算，也就是逐顶点的光照和逐片元的光照。
逐顶点的话，性能要好一些，它只计算顶点的光照，其他部分就通过插值得到，这样的话节省了很多运算。
逐个片元的话，计算性能开销要大一些，但是最终的效果会更好一些。
一般的话，我了解到，手机上使用逐顶点的关照要多一些。

### 纹理是什么

一张 2D 贴图，按照一定映射关系，根据三角形面上一点的坐标，找到其在纹理上的对应坐标并获得它的 RGB 颜色，当然也可能是其他贴图，比如凹凸贴图、法线贴图。
使用纹理的话，我个人理解是为了方便、节省计算，例如我们把预先渲染的结果制作为贴图，那么之后就可以直接读取纹理，而不用再次计算了。
如果是法线贴图的话，就更方便对光照计算进行调整。

### 简述 mipmap

mipmap 其实是一个问题常见的解决方法之一。
问题场景是：当物体处于远处的时候，在屏幕上占据的像素就很小了，这也就导致两个相邻屏幕像素点，它们在纹理上的对应坐标，其实相隔很远，也就导致了走样。
那么怎么解决这个问题呢，就是mipmap。如果物体太远，我们就用低分辨率的贴图，太近就用高分辨率的嘛。
那么有这个思路，就涉及两个问题，一个是不同分辨率的贴图怎么搞出来，一个是我怎么知道该用哪个分辨率的贴图。

首先说第一个点，一般来讲是每4个像素合并为一个，形成低分辨率贴图。然后这样递归下去，就能生成更低分辨率的贴图。
然后是怎么选择贴图，就是通过计算相邻像素点在纹理贴图上两个点的距离，根据这个距离大小，确定使用哪一个分辨率的贴图。

当然还能延申一下，比如三线性插值，就是用两个相邻分辨率的贴图的结果，再次插值。
还有各向异性mipmap，它解决的就是说远处物体在纹理贴图上是矩形的情况。

这个就是我理解的mipmap了。
哦还有缺点，缺点就是，因为需要生成多种分辨率的贴图，所以使用的存储空间会更大。

### 法线贴图
先说法线贴图是干什么的。
举个例子吧，我们假定一个平面，假设就是一个墙壁，砖墙，用那个工地红砖砌成的墙。
问题就是，这面墙只有一个平面，要怎么让它更真实呢。
比较朴素的想法就是增加面数，用更多的三角面来建模描绘细节，但是这个就性能开销太大嘛。
实际上啊，更细致的建模主要还是得到更真实的光照嘛，那么转念一想呢，光照又来源于入射向量和法线的夹角。

所以就有了法线贴图，通过法线贴图，我们计算墙面的光照的时候，不用这个墙面的法向量，因为墙面的法向量都是一个方向嘛，算出来的结果就会看着很平。那我们用啥呢，就用从法线贴图里读取到的法向量，这样一来，相比于增加面数，我们就可以通过相对低成本的修改不同坐标在法线贴图里的法向量朝向，实现更真实的阴影、高光效果。

这个就是我理解的法线贴图的作用。

### 切线空间法线贴图

关于切线空间的法线贴图。
我理解，实际上我们的目的是去修改某一点的法线向量，那么存储方式应该是怎么方便怎么来。
那么最朴素的想法还是我按照世界空间、或者模型空间的坐标去存储这个法线贴图。
不过这么搞虽然看起来很方便，是吧，我去法线贴图里读一下，然后转换到和光照计算在同一个空间里，就能算了。
但是实际上不是那么好用，比如说我的这个模型发生了一些形变，就会导致当前的法线贴图不在适用了。
这个就比较麻烦了，如果要解决这个问题，相当于我的模型稍微动一下，我就得专门为这个新姿势的模型再准备一张法线贴图。

OK，下面就是切线空间的法线贴图。
我们说到这个问题是，一般的（世界空间、模型空间的）法线贴图没法搞定模型稍微动一下。
当然有解决办法，就是切线孔家的法线贴图。
我先用一句话概括一下啊，对于模型上的一个点，我们用它的法线（N）、和它在空间中 u增量方向（T'）、v增量方向（B'）的这三个方向向量，进行一个施密特正交化，就得到的一个局部坐标系（TBN），也就是常说的 TBN 矩阵。
对于每一个点我们都可以得到这样的一个 TBN 矩阵。

那么现在的法线贴图里存储的是什么呢，其实就是对这个局部坐标系中 N 方向的扰动，也就是对这一点原本法向量的扰动。
我们在计算这个地方的法线时，TBN 矩阵就是我这一点的局部坐标系，我原本的法向量就是 TBN 的 N 这个向量，把法线贴图里读出来的数据 乘以 TBN 矩阵，就得到了修改后的法向量。
这也可以解释为什么切线空间法线贴图总是大部分是蓝色。因为，大部分的点法向量要么就没有变换，要么只是稍微改一改法向量，法线贴图又是用 RGB 去存储 TBN 这三个分量的，那么很显然 RGB 的 B 大部分都是接近 1 的。
### 法向量的变换为什么是乘以逆矩阵

因为要与变换后的面保持垂直。
假设一个法向量为 A,B,C,0，其为平面 Ax+By+Cz=0 的法向量，写成向量形式则为：
$$
\begin{bmatrix}A&B&C&0\end{bmatrix}\begin{bmatrix}x\\y\\z\\1\end{bmatrix}=0
$$
现在进行投影变换，那么平面上所有点都要乘以 M，为了保持结果仍为 0，保持垂直，则法向量要乘以 M 的逆
$$
\begin{aligned}
\begin{bmatrix}A&B&C&0\end{bmatrix}M^{-1}M\begin{bmatrix}x\\y\\z\\1\end{bmatrix}=0
\\({M^{T}}^{-1}\begin{bmatrix}A\\B\\C\\0\end{bmatrix})^{T}M\begin{bmatrix}x\\y\\z\\1\end{bmatrix}=0
\end{aligned}
$$
最终得到，法向量需要乘以 M 的逆矩阵。

### 逐vertex光照和逐fragment光照的区别

逐顶点光照是在 vertex shader 中计算光照，随后在 fragment shader 中通过插值得到 fragment 中的光照颜色

逐 fragment 光照是在 fragment shader 中计算光照，这样的效果会更好，但是呢，计算性能的开销比较大。

一般来说，我了解到，手机上可能逐顶点光照用得会多一些。

### Phong 和 Blinn-Phong

Phong 式模型的话，它是把光照分为三种：
环境光(Ambient)、漫反射光(Diffuse)和镜面(Specular)光照。
环境光即来自其它物体，不是直接光源的光照，我看 games101 和我参考的 软渲染器，都是用一个常数代表了。在Phong模型中是一个常数。
漫反射即粗糙物体表面均匀的反射光线到各个方向所产生的光照效果。
镜面光照的话就是高光，由光滑物体表面平行地向一个方向反射出来的光照效果。

Blinn-Phong 模型的话， 区别在于镜面反射的计算上，Blinn-Phong 模型它引入了一个半程向量（halfway vector）的概念，用的是法线和半程向量之间的夹角来计算镜面反射。半程向量是视线方向和反射向量之间的夹角。

### 光线追踪
光线追踪的话，嗯，就是说在摄像机前面放一个屏幕，从摄像机出发，遍历这个屏幕上的每个像素点，每次得到一个向量。从这个向量出发，计算这个视线是否命中一个物体，命中之后，就计算出反射方向、折射方向，递归式的去计算出下一个命中物体。

我自己实现的是递归式的光线追踪。

#### AABB（轴对齐包围盒 Axis Aligned Bounding Box）

光线先对包围盒求交，如果与包围盒无交点，则不做判断。如果有交点，则对包围盒中的物体求交。

空间划分：八叉树，KD树，BSP树，BVH树
### KD 树、BVH 树
https://zhuanlan.zhihu.com/p/231704545


#### 我做了什么

关于 tinyrender 软渲染器

bresenham 直线绘制算法
光栅化
背面剔除
z-buffer 解决前后遮挡问题
正交投影、透视投影
着色器
切线空间法线贴图
阴影映射
